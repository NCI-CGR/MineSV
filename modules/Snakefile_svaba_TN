#!/usr/bin/env python3

import os

# snakemake -s modules/Snakefile_svaba_TN --cluster "qsub -o /DCEG/CGF/Bioinformatics/Production/Bari/Struct_var_pipeline_dev/snake_tests/ -j y -pe by_node 2" --jobs 100 --latency-wait 300
    # tested with chr3part bams - works!

conf = os.environ.get("conf")
configfile: conf
execDir = config['execDir']
parentDir = config['outDir']
workingDir = parentDir + 'svaba_TN/'
dataDir = config['inDir']
bamList = config['inFile']
nt = config['maxThreads']
ref = config['refGenome']
chrPrefix = config['chrPrefix']
# logDir = config['logDir'] # not implemented yet

# METRICS1 = ['LO', 'LR', ]  # sample-level parameters to plot
# METRICS2 = ['QUAL']  # sample-level parameters to plot

refNoExt = os.path.splitext(ref)[0]

# read in a file where each row has the pair name, tumor file name, normal file name
# this could change depending on functionality required, eg
# if tumor and normal bams have the same name but are in different directories
# (currently assuming same directory for T and N)
bamDict = {}
with open(bamList) as f:
    for line in f:
        (pair, tumor, normal) = line.split()
        bamDict[pair] = (dataDir + tumor, dataDir + normal)


def get_tumor_bam(wildcards):
    (tumor, normal) = bamDict[wildcards.sample]
    return tumor


def get_tumor_index(wildcards):
    (tumor, normal) = bamDict[wildcards.sample]
    return tumor + '.bai'


def get_normal_bam(wildcards):
    (tumor, normal) = bamDict[wildcards.sample]
    return normal


def get_normal_index(wildcards):
    (tumor, normal) = bamDict[wildcards.sample]
    return normal + '.bai'


rule all:
    input:
        workingDir + 'summary.txt'#,
        # expand(workingDir + 'plots/{sample}.{metric1}.png', sample=bamDict.keys(), metric1=METRICS1),
        # expand(workingDir + 'plots/{sample}.{metric2}.png', sample=bamDict.keys(), metric2=METRICS2),
        # expand(workingDir + 'svaba/{sample}.svaba.somatic.sv.vcf', sample=bamDict.keys())

rule svaba_index_ref:
    input:
        ref
    output:
        d = refNoExt + '.dict',
        amb = ref + '.amb',
        ann = ref + '.ann',
        bwt = ref + '.bwt',
        fai = ref + '.fai',
        pac = ref + '.pac',
        sa = ref + '.sa'
    shell:
        'module load bwa samtools Picard;'
        'bwa index -a bwtsw {input};'
        'samtools faidx {input};'
        'picard CreateSequenceDictionary REFERENCE={input} OUTPUT={output.d}'

rule svaba_call:
    input:
        t = get_tumor_bam,
        tIndex = get_tumor_index,
        n = get_normal_bam,
        nIndex = get_normal_index,
        ref = ref,
        d = refNoExt + '.dict',
        amb = ref + '.amb',
        ann = ref + '.ann',
        bwt = ref + '.bwt',
        fai = ref + '.fai',
        pac = ref + '.pac',
        sa = ref + '.sa'
    output:
        workingDir + 'calls/{sample}.alignments.txt.gz',
        workingDir + 'calls/{sample}.bps.txt.gz',
        workingDir + 'calls/{sample}.contigs.bam',
        workingDir + 'calls/{sample}.discordant.txt.gz',
        workingDir + 'calls/{sample}.log',
        workingDir + 'calls/{sample}.svaba.germline.indel.vcf',
        workingDir + 'calls/{sample}.svaba.germline.sv.vcf',
        workingDir + 'calls/{sample}.svaba.somatic.indel.vcf',
        workingDir + 'calls/{sample}.svaba.somatic.sv.vcf',
        workingDir + 'calls/{sample}.svaba.unfiltered.germline.indel.vcf',
        workingDir + 'calls/{sample}.svaba.unfiltered.germline.sv.vcf',
        workingDir + 'calls/{sample}.svaba.unfiltered.somatic.indel.vcf',
        workingDir + 'calls/{sample}.svaba.unfiltered.somatic.sv.vcf'
    threads: nt
    params:
        opath = workingDir + 'calls/',
        epath = execDir + 'sv_callers/'
    shell:
        'module load gcc/4.8.4;'
        '{params.epath}svaba/bin/svaba run \
            -p {threads} \
            -G {input.ref} \
            -t {input.t} \
            -n {input.n} \
            -a {params.opath}{wildcards.sample}'

# this rule allows custom filtering, in addition to relying on the built-in filtered files
# rule svaba_basic_filter:
#     input:
#         workingDir + 'calls/{sample}.svaba.unfiltered.somatic.sv.vcf'
#     output:
#         workingDir + 'custom_filtered/{sample}.svaba.filtered.somatic.sv.vcf'
#     shell:
#         # awk statement to filter as in breakdancer

#     params:
#         path = parentDir + 'scripts/',
#         qual_threshold = 30,
#         num_reads = 3
#     shell:
#         '{params.path}breakdancer_somatic_filtering.sh {input} {params.qual_threshold} {params.num_reads} > {output}'
# filter = PASS  -- this one doesn't need the special vcf per-genotype stuff
# AD > 10? num of supporting reads
# LR < 1?
# LO > 30?
# QUAL > 30? -- this one doesn't need the special vcf per-genotype stuff

# rule svaba_somatic_distributions1:  # sample-level parameters
#         input:
    #     workingDir + 'calls/{sample}.svaba.unfiltered.somatic.sv.vcf'
    # output:
    #     workingDir + 'plots/{sample}.{metric1}.png'
    # params:
    #     path = parentDir + 'scripts/',
    #     headerRow = 0
    # shell:
    #     'module load python3;'
    #     'python3 {params.path}plot_vcf_distribution.py {input} {params.headerRow} {wildcards.metric1} {output}'

# rule svaba_somatic_distributions2:  # variant-level parameters
#         input:
    #     workingDir + 'calls/{sample}.svaba.unfiltered.somatic.sv.vcf'
    # output:
    #     workingDir + 'plots/{sample}.{metric2}.png'
    # params:
    #     path = parentDir + 'scripts/',
    #     headerRow = 0
    # shell:
    #     'module load python3;'
    #     'python3 {params.path}plot_distribution.py {input} {params.headerRow} {wildcards.metric2} {output}'

rule svaba_summary:
    input:
        expand(workingDir + 'calls/{sample}.svaba.somatic.sv.vcf', sample=bamDict.keys())
    output:
        workingDir + 'summary.txt'
    shell:
        'grep -vc "^##" {input} >> {output}'
        # weirdly, this throws an error if the grep result is 0, so this way it will always detect at least the header row
