{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCCA-SV benchmark notebook\n",
    "The notebook is to carry on MoCCA-SV benchmark. The input files and options are all specified in the [\"Configuration\" cell](#Configuration).  The outputs of this benchmark are two CSV files, saved from pandas data frames, including the performance metrics, such as TP, FP, F1, etc.  The performance are subsetted by SV types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initial setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/gigantor/ifs/DCEG/Projects/CoherentLogic/SV/mocca-bench\n",
      "Currently Loaded Modulefiles:\n",
      "  1) tmux/2.5\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/nfs/gigantor/ifs/DCEG/Projects/CoherentLogic/SV/mocca-bench\n",
    "! module list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "The truth VCF file has been converted into the bed format, specified by ***TRUTH_BED***, whereas, the bed output from MoCCA-SV is named by ***COMP_BED***. The file ***INCLUDED_BED*** is to specified the regions to be included in the benchmark; it could be set to emtpy (i.e., \"\"), if it is not appliable. \n",
    "\n",
    "***calleres*** are those SV callers used in the MoCCA-SV pipelines, and the order is matched to their positions in the MoCCA-SV output bed file (*COMP_BED*).  By default, they are started from the 4th column in *COMP_BED*, which can be adjusted by the variable *first_caller_column*. \n",
    "\n",
    "***ensemble*** is to specified the ensemble prediction supported by any of one (or more) SV caller. The numeric list like \"[10,12]\" is to specify the caller position in the final combined bed file.  During the benchmark, we take the intersection between *TRUTH_BED* and *COMP_BED*.  The result bed file contains many columns: the first 6 are those from *TRUTH_BED* by default, and the remaining columns are those from *COMP_BED* in the order.  For instance, in this particular denomstration, \"svaba\" and \"manta\" are 1st and 3rd SV callers and located in 4th and 6th column in *COMP_BED*.  Their column positions are moved to 10th and 12th after the combination, which are specified as  ***svaba_or_manta\":[10,12]*** as defined in *ensemble*. \n",
    "\n",
    "***OUTFN*** specifies the CSV file for the performance output, and ***SVTYPEFN*** specifies another CSV files for the benchmark performance segmented by SVTYPE and *SV_SIZE_BIN*. \n",
    "\n",
    "The remaining variables in the Configuration cell are more constant and are not likely to be modified between runs. \n",
    "+ TMP: Specifies the folder to keep temporary intermediate results.  It needs to be named differently if multiple benchmark are run simultaneously. \n",
    "+ N: Specifies the number of base pairs to be padded for each insertion\n",
    "+ MIN_OVP: The minimum reciprocal overlap to be considered as a hit.\n",
    "+ MAX_INS_GAP: This is an emperical cutoff.  We take intrachromosomal SVs with size less than MAX_INS_GAP as \"insertion\".\n",
    "+ genome_file: Specifies the chromsome sizes of the reference genome, and to be used with bedtools slop. \n",
    "+ first_caller_column: First caller column position in *COMP_BED*, which is 1-based.\n",
    "+ caller_cnt_column: There is one column \"caller_cnt\" in *COMP_BED*, which is right after all SV caller columns by default. \n",
    "+ SV_SIZE_BIN: Specifies the bin sizes of interest in python format, which is to be used in the table output saved in *SVTYPEFN*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting for GIAB\n",
    "\n",
    "# TRUTH_BED=\"data/my-tp-base.bed\"\n",
    "# COMP_BED=\"data/intrachromosomal_SVs_AJ_2x250_son\"\n",
    "# INCLUDED_BED=\"data/HG002_SVs_Tier1_noVDJorXorY_v0.6.2.bed\" # Assign it to \"\", if there is not included be file\n",
    "# callers = ['svaba', 'breakdancer', 'manta']\n",
    "# ensemble={\"svaba_or_manta\":[10,12],\n",
    "#           \"svaba_or_breakdancer\":[10,11],\n",
    "#           \"manta_or_breakdancer\":[12,11],\n",
    "#           \"any_one\":[10,11,12]\n",
    "#           }\n",
    "# OUTFN=\"GIAB_performance.csv\"\n",
    "# SVTYPEFN=\"GIAB_SVtype.csv\"\n",
    "\n",
    "\n",
    "## Setting for IS1\n",
    "# svaba   breakdancer     delly   manta   gridss\n",
    "TRUTH_BED=\"data/my_is1.bed\" \n",
    "COMP_BED=\"../test/test_gridss_TN/output/compare_and_annotate/intrachromosomal_SVs_IS1\"\n",
    "INCLUDED_BED=\"\"\n",
    "columns=[10,11,12,13,14]\n",
    "callers=[\"svaba\", \"breakerdancer\", \"delly\", \"manta\", \"gridss\"]\n",
    "OUTFN=\"IS1_performance.csv\"\n",
    "SVTYPEFN=\"IS1_SVtype.csv\"\n",
    "ensemble={\"svaba_or_gridss\":[10,14],\n",
    "          \"delly_or_gridss\":[12,14],\n",
    "          \"manta_or_gridss\":[13,14],\n",
    "          \"svaba_or_manta_or_gridss\":[10,13,14]\n",
    "         }\n",
    "\n",
    "TMP=\"./TMP\" #  temporary file is to be used for keep temporary intermediate results, will be overwrriten for each run\n",
    "N=500 # for padding insertion\n",
    "MIN_OVP=0.7 # for minimum reciprocal overlap\n",
    "MAX_INS_GAP=20 # assume that breakpoint gap of the insert is no more than 20\n",
    "genome_file = \"./data/hg19_wo_chr.genome\" \n",
    "TRUTH_BED_COLS=6 # the turth bed file contains 6 columns\n",
    "first_caller_column= 4 # first caller position in MoCCA-SV; 1-based as to be used with awk\n",
    "caller_cnt_column = len(callers) + 4 # caller_count column position; 1-based \n",
    "\n",
    "import numpy as np\n",
    "SV_SIZE_BIN=[50, 100, 300, 1000, np.Inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Several helper functions are defined here\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import subprocess \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_shell(cmd, get_single_number=False, is_df=False):\n",
    "    print(\"Run: \"+cmd)\n",
    "    try:\n",
    "       grepOut = subprocess.check_output(cmd, shell=True, universal_newlines=True, stderr=subprocess.STDOUT)                       \n",
    "    except subprocess.CalledProcessError as grepexc:                                                                                                   \n",
    "        print(\"Error code\", grepexc.returncode,'; ', grepexc.output)\n",
    "    \n",
    "    rv = None\n",
    "    if get_single_number:\n",
    "        rv=int(grepOut)\n",
    "    else:\n",
    "        rv=grepOut.rstrip().split(\"\\n\")\n",
    "    \n",
    "    if is_df:\n",
    "        rv=pd.DataFrame([x.split('\\t') for x in rv])\n",
    "        \n",
    "    return rv\n",
    "\n",
    "def create_tmp_file(fn, tempdir=TMP, empty_file=False):\n",
    "    tmp_fn = os.path.join(TMP, fn)\n",
    "    \n",
    "    if os.path.exists(tmp_fn):\n",
    "        os.remove(tmp_fn)\n",
    "    \n",
    "    if empty_file:\n",
    "        os.system(\"touch %s\" % (tmp_fn))\n",
    "    \n",
    "    return(tmp_fn)\n",
    "   \n",
    "os.system(\"mkdir -p %s\" % (TMP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Intersect with the included region if available\n",
    "\n",
    "In the case of GIAB benchmark dataset, low complexity regions and complicated SV regions were excluded. Accordingly, we take only the truth SVs and predicted SVs within the included regions.\n",
    "\n",
    "This step is optional is ***INCLUDED_BED*** is not defined or empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_bed1=TRUTH_BED\n",
    "comp_bed1=COMP_BED\n",
    "\n",
    "if INCLUDED_BED is None or INCLUDED_BED==\"\":\n",
    "    print(\"There is no included region specified!\")\n",
    "else:\n",
    "    # print (\"do something\")\n",
    "    truth_bed1 = create_tmp_file(\"truth_included.bed\")\n",
    "    comp_bed1 = create_tmp_file(\"comp_included.bed\")\n",
    "    cmd1=\"bedtools intersect -a %s -b %s -f 1.0000000 -u > %s\" % (TRUTH_BED, INCLUDED_BED, truth_bed1)\n",
    "    cmd2=\"bedtools intersect -a %s -b %s -f 1.0000000 -u > %s\" % (COMP_BED, INCLUDED_BED, comp_bed1)\n",
    "    _ = run_shell(cmd1)\n",
    "    _ = run_shell(cmd2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Cluster MoCCA-SV to have the unique ID\n",
    "After excluding SV not within the regions specified by *INLCUDED_BED*, we cluster MoCCA-SV predictions and assign a unique ID. The column position of the unique ID is kept by the variable *cluster_last_col*.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_cluster = os.path.join(TMP, \"comp_cluster.bed\")\n",
    "\n",
    "_ = run_shell(\"bedtools cluster -i %s > %s\" % (comp_bed1, comp_cluster))\n",
    "\n",
    "cluster_last_col = run_shell(\"awk 'NR==1{print NF}' %s\" %(comp_cluster), get_single_number=True)              \n",
    "print(\"last column pos: \", cluster_last_col)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Padding the insertions\n",
    "In this step, each insertion are padded to extend 500 bp to each side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_bed2=create_tmp_file(\"truth_padded.bed\")\n",
    "comp_bed2=create_tmp_file(\"comp_padded.bed\")\n",
    "\n",
    "ins_bed=create_tmp_file(\"ins_padded.bed\", empty_file=True)\n",
    "oth_bed=create_tmp_file(\"others_padded.bed\", empty_file=True)\n",
    "cmd = \"bedtools slop -g %s  -b %s \"; \n",
    "    \n",
    "pad_truth_cmd = \"\"\" \n",
    " awk -v OFS='\\\\t' '{ \n",
    "    if($5 == \"INS\") \n",
    "        print $0 > \"%s\"; \n",
    "    else \n",
    "        print $0 > \"%s\";\n",
    "    }' %s > /dev/null ; \n",
    "  cat %s >%s ; \n",
    "  bedtools slop -i %s -g %s  -b %s >> %s ;\n",
    "\"\"\" % (ins_bed, oth_bed, truth_bed1, oth_bed, truth_bed2, ins_bed, genome_file, N, truth_bed2)\n",
    "        \n",
    "_= run_shell(pad_truth_cmd)\n",
    "\n",
    "pad_comp_cmd = \"\"\" \n",
    " awk -v OFS='\\\\t' '{ \n",
    "    if($3-$2 <= %d) \n",
    "        print $0 > \"%s\"; \n",
    "    else \n",
    "        print $0 > \"%s\";\n",
    "    }' %s > /dev/null; \n",
    "  cat %s > %s;  \n",
    "  bedtools slop -i %s -g %s  -b %s >> %s;\n",
    "\"\"\" % (MAX_INS_GAP, ins_bed, oth_bed, comp_bed1, oth_bed, comp_bed2, ins_bed, genome_file, N, comp_bed2)\n",
    "        \n",
    "_= run_shell(pad_comp_cmd)\n",
    "\n",
    "\n",
    "# pad_comp_cmd = \"\"\" \n",
    "#  awk -v OFS='\\\\t' '{ \n",
    "#     cmd = \"bedtools slop -g %s  -b %d \"; \n",
    "#     if($3-$2 <= %d) \n",
    "#         print $0 | cmd; \n",
    "#     else \n",
    "#         print $0 \n",
    "#     }' %s > %s \n",
    "# \"\"\" % (genome_file, N, MAX_INS_GAP, comp_bed1, comp_bed2)\n",
    "        \n",
    "# _= run_shell(pad_comp_cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get the intersections between the truth bed and the compute bed \n",
    "The processed TRUTH_BED and COMP_BED are intersected using bedtools. The intrachromosomal SVs predicted by MoCCA-SV with at least ***MIN_OVP*** reciprocal overap with the truth bed file are considered as TP.  \n",
    "\n",
    "We repeat the intersection three times here to capture different information.\n",
    "+ isec_bed: keep columns/information from both the truth bed and compute bed files of TPs.\n",
    "+ isec_truth_bed: keep only columns from the truth bed of those TPs.\n",
    "+ isec_fp_bed: keep only columns from ***COMP_BED***, which are not matched with any ***TRUTH_BED***, i.e., those are FPs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isec_bed = create_tmp_file(\"isec.bed\")\n",
    "\n",
    "isec_cmd = \"\"\"\n",
    "             bedtools intersect -a %s -b %s -wa -wb -f %f -r > %s\n",
    "           \"\"\" % (truth_bed2, comp_bed2, MIN_OVP, isec_bed)\n",
    "_=run_shell(isec_cmd)\n",
    "\n",
    "isec_truth_bed = create_tmp_file(\"isec_truth.bed\")\n",
    "isec_truth_cmd = \"\"\"\n",
    "             bedtools intersect -a %s -b %s -u -f %f -r > %s\n",
    "           \"\"\" % (truth_bed2, comp_bed2, MIN_OVP, isec_truth_bed)\n",
    "_=run_shell(isec_truth_cmd)\n",
    "\n",
    "\n",
    "### Repeat the similar command but to keep fp from MoCCA\n",
    "isec_fp_bed = create_tmp_file(\"isec_fp.bed\")\n",
    "\n",
    "isec_fp_cmd = \"\"\"\n",
    "             bedtools intersect -a %s -b %s -v -f %f -r > %s\n",
    "           \"\"\" % (comp_bed2, truth_bed2, MIN_OVP, isec_fp_bed)\n",
    "_=run_shell(isec_fp_cmd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summary the results\n",
    "#### 4.1. Collect counts of SV predictions, and true positives\n",
    "+ ***tps*** is the python list to keep true positives, based on ***isec_bed***.  \n",
    "+ ***all_callers*** is a list to keep the name of callers (including the ensemble callers).\n",
    "+ ***preds*** is to keep the count of SV predictions from the processed ***COMP_BED***\n",
    "+ ***svtype*** is a python DataFrame to keep  SV type and interval size of the true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counter the numbers of the true predictions (tps) and the all predictions (preds) \n",
    "\n",
    "tps=[] # Count \n",
    "all_callers=[]\n",
    "preds=[]\n",
    "\n",
    "# svtype is to keep a record of SV types and Lengths \n",
    "svtype=pd.DataFrame(columns=['Caller', 'SVtype', \"SVlen\"])\n",
    "\n",
    "svtype_truth=None\n",
    "for i,caller in enumerate(callers):\n",
    "    tp_cmd = \"\"\"\n",
    "            awk  '{if($%d==\"orig\") print $4}' %s | sort -u |wc -l\n",
    "        \"\"\" % (i + first_caller_column + TRUTH_BED_COLS, isec_bed)\n",
    "    tps.append(run_shell(tp_cmd, get_single_number=True))\n",
    "    \n",
    "    pred_cmd = \"\"\"\n",
    "            awk  '{if($%d==\"orig\") print}' %s | wc -l\n",
    "        \"\"\" % (i + first_caller_column, comp_bed1)\n",
    "    preds.append(run_shell(pred_cmd, get_single_number=True))\n",
    "    \n",
    "    \n",
    "    tp_svtype_cmd = \"\"\"\n",
    "            awk  '$%d==\"orig\"' %s | awk -v OFS='\\t' '{if(!seen[$4]++) print $5,$6}' \n",
    "        \"\"\" % (i + first_caller_column + TRUTH_BED_COLS, isec_bed)\n",
    "    tp_svtype=run_shell(tp_svtype_cmd, is_df=True)\n",
    "    \n",
    "    svtype=svtype.append(pd.DataFrame({\"Caller\":caller, \"SVtype\":tp_svtype.iloc[:,0], \"SVlen\":tp_svtype.iloc[:,1]}))\n",
    "    \n",
    "    \n",
    "    all_callers.append(caller)\n",
    "\n",
    "print(all_callers)\n",
    "print(preds)\n",
    "print(tps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_callers)\n",
    "print(preds)\n",
    "print(tps)\n",
    "print(caller)\n",
    "print(tp_svtype_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Continue to collect counts for the ensemble caller defined by the variable ***ensemble***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on the ensemble call \n",
    "# get prediction count using bedtools cluster\n",
    "\n",
    "\n",
    "for k in ensemble.keys():\n",
    "    print(k)\n",
    "    \n",
    "    tp_tmp_file=create_tmp_file(\"%s_tp.tmp\" % k, empty_file=True)\n",
    "    pred_tmp_file=create_tmp_file( \"%s_pred.tmp\" % k, empty_file=True)\n",
    "    \n",
    "\n",
    "    for i in ensemble[k]:\n",
    "        # count tp from the intersection\n",
    "        cmd= \"\"\"\n",
    "                awk   '$%d==\"orig\"' %s >> %s\n",
    "             \"\"\" % (i, isec_bed, tp_tmp_file)\n",
    "        _=run_shell(cmd)\n",
    "        \n",
    "        # count pred from the clustered MoCCA-SV\n",
    "#         cmd2=\"\"\"\n",
    "#                 awk   '$%d==\"orig\"' %s >> %s\n",
    "#              \"\"\" % (i-TRUTH_BED_COLS, comp_cluster, pred_tmp_file)\n",
    "#         _=run_shell(cmd2)\n",
    "        \n",
    "        # count fp from isec_fp_bed and cluster again as the count of fp\n",
    "        cmd2=\"\"\"\n",
    "                awk  '$%d==\"orig\"' %s >> %s\n",
    "             \"\"\" % (i-TRUTH_BED_COLS, isec_fp_bed, pred_tmp_file)\n",
    "        _=run_shell(cmd2)\n",
    "    \n",
    "        \n",
    "    tp=run_shell(\"cut -f 4 %s | sort -u |wc -l\" % (tp_tmp_file), get_single_number=True)\n",
    "    # pred=run_shell(\"cut -f %d %s | sort -u  |wc -l\" % (cluster_last_col, pred_tmp_file), get_single_number=True)\n",
    "    # get the count of prediction in the othe way: Count the number of FP\n",
    "    # I may need to remove comp_cluster file as it is not of use any more\n",
    "    fp = run_shell(\"\"\"\n",
    "             bedtools cluster -i %s | cut -f %d | sort -u |wc -l  \n",
    "           \"\"\" % (pred_tmp_file, cluster_last_col),  get_single_number=True)\n",
    "    pred = tp + fp\n",
    "    print(tp)\n",
    "    print(pred)\n",
    "    \n",
    "    # get svtype from tp_tmp_bed\n",
    "    tp_svtype_cmd = \"\"\"\n",
    "                    cat %s | awk -v OFS='\\t'  '{if(!seen[$4]++) print $5,$6}' \n",
    "                \"\"\" % (tp_tmp_file)\n",
    "    tp_svtype=run_shell(tp_svtype_cmd,is_df=True)\n",
    "\n",
    "    svtype=svtype.append(pd.DataFrame({\"Caller\":k, \"SVtype\":tp_svtype.iloc[:,0], \"SVlen\":tp_svtype.iloc[:,1]}))\n",
    "    \n",
    "    all_callers.append(k)\n",
    "    tps.append(tp)\n",
    "    preds.append(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Continue to collect counts for the MoCCA-SV build-in ensemble caller.\n",
    "\n",
    "In the MoCCA-SV bed file outptu, there is a column \"caller_cnt\" defined in the position ***caller_cnt_column***. Accordingly, we may select ensemble SV predictions supported by one or more SV callers: e.g., any_1, any_2, and any_3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the ensemble call built in MoCCAV, that is, caller_cnt_column (+ TRUTH_BED_COLS for intersect file)\n",
    "\n",
    "for i,_ in enumerate(callers, 1):\n",
    "    caller=\"any_%d\" % i\n",
    "    print(caller)\n",
    "    \n",
    "    tp_cmd = \"\"\"\n",
    "            awk  '{if($%d>=%d) print $4}' %s | sort -u |wc -l\n",
    "        \"\"\" % (caller_cnt_column + TRUTH_BED_COLS, i, isec_bed)\n",
    "    tp = run_shell(tp_cmd, get_single_number=True)\n",
    "    tps.append(tp)\n",
    "    \n",
    "    fp_cmd = \"\"\"\n",
    "            awk  '{if($%d>=%d) print $0}' %s | bedtools cluster | cut -f %d| sort -u | wc -l\n",
    "        \"\"\" % (caller_cnt_column, i, isec_fp_bed, cluster_last_col)\n",
    "    \n",
    "    fp = run_shell(fp_cmd, get_single_number=True)\n",
    "    pred = tp + fp\n",
    "    preds.append(pred)\n",
    "    \n",
    "    \n",
    "    tp_svtype_cmd = \"\"\"\n",
    "            awk  '$%d>=%d' %s | awk -v OFS='\\t' '{if(!seen[$4]++) print $5,$6}' \n",
    "        \"\"\" % (caller_cnt_column + TRUTH_BED_COLS, i, isec_bed)\n",
    "    \n",
    "    tp_svtype=run_shell(tp_svtype_cmd,is_df=True)\n",
    "\n",
    "    svtype=svtype.append(pd.DataFrame({\"Caller\":caller, \"SVtype\":tp_svtype.iloc[:,0], \"SVlen\":tp_svtype.iloc[:,1]}))\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_callers.append(caller)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. Summerizee the performance of SV callers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect SVtype and SVlength from the truth bed file\n",
    "truth_df=pd.read_csv(TRUTH_BED, sep=\"\\t\", names=[\"chrom\", \"start\", \"end\", \"name\", \"svtype\", \"svlen\"])\n",
    "\n",
    "truth_df.head()\n",
    "svtype=svtype.append(pd.DataFrame({\"Caller\":\"Truth\", \"SVtype\":truth_df[\"svtype\"], \"SVlen\":truth_df[\"svlen\"]}))\n",
    "\n",
    "svtype = svtype.assign(SVlen=lambda df:df.SVlen.astype(int))\n",
    "sv_cnt = svtype.groupby(['Caller', 'SVtype', pd.cut(svtype.SVlen, SV_SIZE_BIN, right=False)]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_cnt.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=sv_cnt.reset_index(name=\"Size\")\n",
    "data.head()\n",
    "\n",
    "fg = sns.catplot(x='SVlen', y='Size', hue='Caller', \n",
    "                        col='SVtype', data=data, kind='bar')\n",
    "fg.set_xlabels('SV size bin (bp)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_cnt = run_shell(\"cat %s | wc -l\" % (TRUTH_BED), get_single_number=True)\n",
    "df = pd.DataFrame({\"Truth\":truth_cnt, \n",
    "                   \"PRED\":preds,\n",
    "                   \"TP\":tps\n",
    "                  }, index=all_callers).assign(\n",
    "                        FP=lambda df:df.PRED-df.TP,\n",
    "                        FN=lambda df:df.Truth-df.TP, \n",
    "                        Sp=lambda df: df.TP/df.PRED, \n",
    "                        Sn=lambda df: df.TP/df.Truth,\n",
    "                        F1=lambda df:2*df.TP/(2*df.TP+df.FP+df.FN)\n",
    "                  )\n",
    "\n",
    "df.index.name=\"Caller\" \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.index.name=\"Caller\"\n",
    "dat = df.reset_index()\n",
    "dat.head()\n",
    "g=sns.scatterplot(x=\"Sn\", y=\"Sp\", data=dat,hue=\"Caller\")\n",
    "g.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5. Save the two tables into CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to files\n",
    "df.to_csv(OUTFN)\n",
    "sv_cnt.unstack(0).to_csv(SVTYPEFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
